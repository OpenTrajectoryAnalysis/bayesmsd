{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "708f38fa",
   "metadata": {},
   "source": [
    "# Likelihood landscapes\n",
    "`bayesmsd` being a Bayesian framework means that its central object is the likelihood function, i.e. the function that---based on the input data---assigns statistical weights to all parameter combinations.\n",
    "\n",
    "The `bayesmsd` package is predominantly focussed on defining, computing, and optimizing this function, i.e. the practical needs for application. For debugging or learning, however, it can also be very instructive to visualize the whole likelihood landscape, instead of blindly trusting the code to find its way through it; this will be the subject of the present example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713d6c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '1'\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import noctiluca as nl\n",
    "import bayesmsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500cad34",
   "metadata": {},
   "source": [
    "We start by generating a simple, subdiffusive data set with $\\text{MSD} = \\sqrt{\\Delta t} \\equiv \\Gamma\\left(\\Delta t\\right)^\\alpha$ with $\\Gamma = 1$ and $\\alpha = 0.5$. We fit a powerlaw (no localization error) to these data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c1b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(84567719)\n",
    "data = bayesmsd.gp.generate((bayesmsd.deco.MSDfun(lambda dt: dt**0.5), 1, 1), T=100, n=20)\n",
    "\n",
    "fit = bayesmsd.lib.NPXFit(data, ss_order=1)\n",
    "fit.parameters['log(σ²) (dim 0)'].fix_to = -np.inf\n",
    "fitres = fit.run(show_progress=True)\n",
    "\n",
    "for name, val in fitres['params'].items():\n",
    "    print(f\"{name:>15s} = {val:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c615af1b",
   "metadata": {},
   "source": [
    "The results look decent, though not perfect; this is expected, because our data set contains relatively little data (20 trajectories à 100 frames each). This means that we expect a broad peak in the likelihood landscape. Let's take a look.\n",
    "\n",
    "We begin by pulling the likelihood function* from the `fit` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bcec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_logL = fit.MinTarget(fit)\n",
    "def log_likelihood(params):\n",
    "    return -neg_logL(neg_logL.params_dict2array(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65cccf9",
   "metadata": {},
   "source": [
    "What's happening here? The core objective of the `fit` is to find parameter values that maximize the likelihood function. Technically, it does so by minimizing the negative (log-)likelihood; we can thus grab the (log-)likelihood function from the internal \"minimization target\". The returned object expects parameter values as a simple numpy array (as required by `scipy.optimize.minimize`); so we construct a little wrapper taking care of the conversion from the more verbose dict structure that e.g. `fitres['params']` employs.\n",
    "\n",
    "This gives us the function `log_likelihood()`, which takes parameters in the same format as `fitres['params']` and gives the corresponding (log-)likelihood values.\n",
    "\n",
    "\\*<font size=1>technically, this is the unnormalized posterior, i.e. it contains the priors applied by `bayesmsd`; it is just not normalized to be a proper posterior distribution.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982e7555",
   "metadata": {},
   "source": [
    "What's left to do now is to evaluate this function on a grid of parameter values and display the resulting landscape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ddbe7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logG, a = np.meshgrid(np.log(np.linspace(0.7, 1.3, 20)), np.linspace(0.3, 0.7, 20))\n",
    "logL = np.nan*np.empty(logG.shape)\n",
    "\n",
    "for i, j in itertools.product(*list(map(range, logL.shape))):\n",
    "    params = {key : val for key, val in fitres['params'].items()} # copy point estimate\n",
    "    params['log(Γ) (dim 0)'] = logG[i, j] # adjust sweeping\n",
    "    params[     'α (dim 0)'] =    a[i, j] # parameters\n",
    "    \n",
    "    logL[i, j] = log_likelihood(params)   # evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03dd13aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "h = plt.pcolormesh(np.exp(logG), a, logL-np.max(logL),\n",
    "                   shading='nearest',\n",
    "                   vmin=-10,\n",
    "                  )\n",
    "\n",
    "plt.scatter(1, 0.5,\n",
    "            marker='x', color='r',\n",
    "            label='true parameters',\n",
    "           )\n",
    "plt.scatter(np.exp(fitres['params']['log(Γ) (dim 0)']),\n",
    "            fitres['params']['α (dim 0)'],\n",
    "            marker='x', color='k',\n",
    "            label='fitted parameters\\n(likelihood maximum)',\n",
    "           )\n",
    "\n",
    "plt.legend()\n",
    "plt.colorbar(h, label='log(L)')\n",
    "plt.xlabel('Γ')\n",
    "plt.ylabel('α')\n",
    "plt.title('Likelihood landscape')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a37498a",
   "metadata": {},
   "source": [
    "And here we go: a direct illustration of the likelihood landscape underlying the fit.\n",
    "\n",
    "## A note of caution: log-likelihoods have a linear scale\n",
    "\n",
    "When studying log-likelihood functions/landscapes, we have to think in absolute terms: a difference of one point in the log-likelihood means that the statistical weights of the corresponding parameter sets differ by a factor of $\\mathrm{e}^1 = 2.72$. Differences of more than a few points in log-likelihood should thus be thought of as very strong distinctions.\n",
    "\n",
    "This point about considering absolute differences is important to keep in mind, especially because the actual values of the log-likelihood function can be enormous in magnitude. They depend on the size of the data set and can easily reach values in the millions and billions. For our relatively small example data set here, this effect is not as drastic, but still notable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898251ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"actual likelihood values:\")\n",
    "print(f\"  minimum:    {np.min(logL):>8.2f}\")\n",
    "print(f\"  maximum:    {np.max(logL):>8.2f}\")\n",
    "print(f\"  difference: {np.max(logL)-np.min(logL):>8.2f}\")\n",
    "print(f\"  ratio:      {np.max(logL)/np.min(logL):>8.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf810baa",
   "metadata": {},
   "source": [
    "So:\n",
    "\n",
    " + we do **not** care that the minimum and maximum of the log-likelihood values in our sweep are within 10% of each other\n",
    " + what we **do** care about is that they are 226 points apart\n",
    " + do not get confused when your maximum log-likelihood evaluates to `-98,165,761`; it just means that the plausible parameters are roughly in the range `[-98,165,755, -98,165,761]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c29a19",
   "metadata": {},
   "source": [
    "## Higher dimensional parameter space\n",
    "The example above has a two dimensional parameter space, which is quite convenient for visualization; but usually we have more parameters than that.\n",
    "\n",
    "In those cases, it often becomes\n",
    "\n",
    " + computationally very expensive to evaluate the likelihood function over a whole grid; this is where the `Profiler` shines\n",
    " + difficult to find a good visualization for a function over a multi-dimensional space.\n",
    "\n",
    "A decent solution for the visualization in a 3D parameter space is a max-projection along the three coordinate axes, which we illustrate here; mostly to provide a reusable code snippet.\n",
    "\n",
    "We follow the same structure as above, but add in some Gaussian localization error, which will be the third parameter in the fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ff7b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(98732457)\n",
    "true_s = 2\n",
    "true_G = 1\n",
    "true_a = 1\n",
    "data = bayesmsd.gp.generate((bayesmsd.deco.MSDfun(lambda dt: true_G*dt**true_a + 2*true_s**2), 1, 1),\n",
    "                            T=100,\n",
    "                            n=20,\n",
    "                           )\n",
    "\n",
    "# visualize the empirical MSD before fitting\n",
    "nl.plot.msd_overview(data)\n",
    "plt.ylim([1, None])\n",
    "plt.show()\n",
    "\n",
    "fit = bayesmsd.lib.NPXFit(data, ss_order=1)\n",
    "fitres = fit.run(show_progress=True)\n",
    "\n",
    "for name, val in fitres['params'].items():\n",
    "    print(f\"{name:>15s} = {val:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36ca29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_logL = fit.MinTarget(fit)\n",
    "def log_likelihood(params):\n",
    "    return -neg_logL(neg_logL.params_dict2array(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c50394c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_s = np.linspace(1.7, 2.3, 10)\n",
    "sweep_G = np.linspace(0.3, 1.7, 10)\n",
    "sweep_a = np.linspace(0.6, 1.4, 10)\n",
    "logs2, logG, a = np.meshgrid(2*np.log(sweep_s), np.log(sweep_G), sweep_a,\n",
    "                             indexing='ij',\n",
    "                            )\n",
    "logL = np.nan*np.empty(logG.shape)\n",
    "\n",
    "for i, j, k in tqdm(itertools.product(*list(map(range, logL.shape)))):\n",
    "    params = {key : val for key, val in fitres['params'].items()} # copy point estimate\n",
    "    params['log(σ²) (dim 0)'] = logs2[i, j, k] # adjust\n",
    "    params[ 'log(Γ) (dim 0)'] =  logG[i, j, k] # sweeping\n",
    "    params[      'α (dim 0)'] =     a[i, j, k] # parameters\n",
    "    \n",
    "    logL[i, j, k] = log_likelihood(params)   # evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6a9c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=[10, 10],\n",
    "                        sharex='col', sharey='row',\n",
    "                        gridspec_kw = {'hspace' : 0.05, 'wspace' : 0.05},\n",
    "                       )\n",
    "\n",
    "max_logL = np.max(logL)\n",
    "vlim = (-10, 0)\n",
    "\n",
    "ax = axs[1, 1]\n",
    "h = ax.pcolormesh(sweep_G, sweep_a,\n",
    "                  np.max((logL-max_logL), axis=0).T,\n",
    "                  shading='nearest',\n",
    "                  vmin=vlim[0], vmax=vlim[1],\n",
    "                 )\n",
    "ax.scatter(true_G, true_a,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(fitres['params']['log(Γ) (dim 0)']),\n",
    "           fitres['params']['α (dim 0)'],\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "ax = axs[1, 0]\n",
    "ax.pcolormesh(sweep_s, sweep_a,\n",
    "              np.max(logL-max_logL, axis=1).T,\n",
    "              shading='nearest',\n",
    "              vmin=vlim[0], vmax=vlim[1],\n",
    "             )\n",
    "ax.scatter(true_s, true_a,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(0.5*fitres['params']['log(σ²) (dim 0)']),\n",
    "           fitres['params']['α (dim 0)'],\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "ax = axs[0, 1]\n",
    "ax.pcolormesh(sweep_G, sweep_s,\n",
    "              np.max(logL-max_logL, axis=2),\n",
    "              shading='nearest',\n",
    "              vmin=vlim[0], vmax=vlim[1],\n",
    "             )\n",
    "ax.scatter(true_G, true_s,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(fitres['params']['log(Γ) (dim 0)']),\n",
    "           np.exp(0.5*fitres['params']['log(σ²) (dim 0)']),\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "plt.colorbar(h, ax=axs[0, 0],\n",
    "             label='log-likelihood',\n",
    "             location='top',\n",
    "             shrink=0.65,\n",
    "             fraction=0.7,\n",
    "            )\n",
    "axs[0, 0].remove()\n",
    "\n",
    "ax = axs[0, 1]\n",
    "ax.scatter(np.nan, np.nan, marker='x', color='r', label='true parameters')\n",
    "ax.scatter(np.nan, np.nan, marker='x', color='k', label='fit results')\n",
    "ax.legend(loc=(-0.75, 0.1))\n",
    "\n",
    "axs[1, 0].set_ylabel('α')\n",
    "axs[1, 0].set_xlabel('σ')\n",
    "axs[0, 1].set_ylabel('σ')\n",
    "axs[0, 1].yaxis.set_tick_params(labelleft=True)\n",
    "axs[0, 1].invert_yaxis()\n",
    "axs[1, 1].set_xlabel('Γ')\n",
    "\n",
    "fig.suptitle('max-projections of likelihood landscape')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff344f8",
   "metadata": {},
   "source": [
    "Note how in this example the prefactor $\\Gamma$ has a broad range of likely values. This is because there is a certain tradeoff between the powerlaw and error terms in the MSD: the data given is consistent with MSDs that have a higher exponent, but therefore higher localization error, or, conversely, somewhat lower exponent and therefore also somewhat lower localization error (c.f. bottom left plot).\n",
    "\n",
    "In practice, results like these simply mean that with the given amount of data we cannot constrain the parameters very precisely: remember that for this example we are studying a data set of 20 trajectories, 100 frames each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f400fcbf",
   "metadata": {},
   "source": [
    "### Tips and tricks\n",
    "\n",
    "When using the above code snippet to study likelihood landscapes, keep in mind that maximum projections can be tricky to interpret, especially when using large grid spacings (i.e. low resolutions; which one might like to do for computational efficiency). Specifically, one might encounter aliasing effects (such as the apparent non-monotonicity around $\\Gamma\\approx 1.2$ in the above example), when the location of the maximum moves from one index in the hidden dimension to the next; it is therefore sometimes useful to\n",
    "\n",
    " + re-run the computation with a finer grid (computationally expensive)\n",
    " + keep in mind that the likelihood function is usually truly pretty smooth (i.e. ignore minor artifacts; can be risky if you are not sure what to take seriously and what not)\n",
    " + in addition to `max()`, also look at `argmax()` maps, i.e. check where in the projected dimension the maximum is located. This can help identify aliasing artifacts.\n",
    " \n",
    "This last point can be done quite easily by adapting the snippet above (replacing `max()` by `argmax()` and changing colormap):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5b9970",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, figsize=[10, 10],\n",
    "                        sharex='col', sharey='row',\n",
    "                        gridspec_kw = {'hspace' : 0.05, 'wspace' : 0.05},\n",
    "                       )\n",
    "\n",
    "max_logL = np.max(logL)\n",
    "vlim = (0, 1)\n",
    "\n",
    "ax = axs[1, 1]\n",
    "h = ax.pcolormesh(sweep_G, sweep_a,\n",
    "                  np.argmax((logL-max_logL), axis=0).T/len(sweep_s),\n",
    "                  shading='nearest',\n",
    "                  vmin=vlim[0], vmax=vlim[1],\n",
    "                  cmap='inferno',\n",
    "                 )\n",
    "ax.scatter(true_G, true_a,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(fitres['params']['log(Γ) (dim 0)']),\n",
    "           fitres['params']['α (dim 0)'],\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "ax = axs[1, 0]\n",
    "ax.pcolormesh(sweep_s, sweep_a,\n",
    "              np.argmax(logL-max_logL, axis=1).T/len(sweep_G),\n",
    "              shading='nearest',\n",
    "              vmin=vlim[0], vmax=vlim[1],\n",
    "              cmap='inferno',\n",
    "             )\n",
    "ax.scatter(true_s, true_a,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(0.5*fitres['params']['log(σ²) (dim 0)']),\n",
    "           fitres['params']['α (dim 0)'],\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "ax = axs[0, 1]\n",
    "ax.pcolormesh(sweep_G, sweep_s,\n",
    "              np.argmax(logL-max_logL, axis=2)/len(sweep_a),\n",
    "              shading='nearest',\n",
    "              vmin=vlim[0], vmax=vlim[1],\n",
    "              cmap='inferno',\n",
    "             )\n",
    "ax.scatter(true_G, true_s,\n",
    "           marker='x', color='r',\n",
    "          )\n",
    "ax.scatter(np.exp(fitres['params']['log(Γ) (dim 0)']),\n",
    "           np.exp(0.5*fitres['params']['log(σ²) (dim 0)']),\n",
    "           marker='x', color='k',\n",
    "          )\n",
    "\n",
    "plt.colorbar(h, ax=axs[0, 0],\n",
    "             label=('maximum location in projected dimension\\n'\n",
    "                    '(as fraction of that dimension\\'s length)'\n",
    "                   ),\n",
    "             location='top',\n",
    "             shrink=0.65,\n",
    "             fraction=0.7,\n",
    "            )\n",
    "axs[0, 0].remove()\n",
    "\n",
    "ax = axs[0, 1]\n",
    "ax.scatter(np.nan, np.nan, marker='x', color='r', label='true parameters')\n",
    "ax.scatter(np.nan, np.nan, marker='x', color='k', label='fit results')\n",
    "ax.legend(loc=(-0.75, 0.1))\n",
    "\n",
    "axs[1, 0].set_ylabel('α')\n",
    "axs[1, 0].set_xlabel('σ')\n",
    "axs[0, 1].set_ylabel('σ')\n",
    "axs[0, 1].yaxis.set_tick_params(labelleft=True)\n",
    "axs[0, 1].invert_yaxis()\n",
    "axs[1, 1].set_xlabel('Γ')\n",
    "\n",
    "fig.suptitle('max-projections of likelihood landscape')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
